{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import re  # For preprocessing\n",
    "import pandas as pd  # For data handling\n",
    "from time import time  # To time our operations\n",
    "from collections import defaultdict  # For word frequency\n",
    "\n",
    "import spacy  # For preprocessing\n",
    "\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-22T18:33:50.102825800Z",
     "start_time": "2023-05-22T18:33:20.868498900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "      raw_character_text                                       spoken_words\n0              Household  SAF 'Floral' Framed Painting (Wood, 30 inch x ...\n1              Household  SAF 'UV Textured Modern Art Print Framed' Pain...\n2              Household  SAF Flower Print Framed Painting (Synthetic, 1...\n3              Household  Incredible Gifts India Wooden Happy Birthday U...\n4              Household  Pitaara Box Romantic Venice Canvas Painting 6m...\n...                  ...                                                ...\n50419        Electronics  Strontium MicroSD Class 10 8GB Memory Card (Bl...\n50420        Electronics  CrossBeats Wave Waterproof Bluetooth Wireless ...\n50421        Electronics  Karbonn Titanium Wind W4 (White) Karbonn Titan...\n50422        Electronics  Samsung Guru FM Plus (SM-B110E/D, Black) Colou...\n50423        Electronics                   Micromax Canvas Win W121 (White)\n\n[50424 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>raw_character_text</th>\n      <th>spoken_words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Household</td>\n      <td>SAF 'Floral' Framed Painting (Wood, 30 inch x ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Household</td>\n      <td>SAF 'UV Textured Modern Art Print Framed' Pain...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Household</td>\n      <td>SAF Flower Print Framed Painting (Synthetic, 1...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Household</td>\n      <td>Incredible Gifts India Wooden Happy Birthday U...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Household</td>\n      <td>Pitaara Box Romantic Venice Canvas Painting 6m...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>50419</th>\n      <td>Electronics</td>\n      <td>Strontium MicroSD Class 10 8GB Memory Card (Bl...</td>\n    </tr>\n    <tr>\n      <th>50420</th>\n      <td>Electronics</td>\n      <td>CrossBeats Wave Waterproof Bluetooth Wireless ...</td>\n    </tr>\n    <tr>\n      <th>50421</th>\n      <td>Electronics</td>\n      <td>Karbonn Titanium Wind W4 (White) Karbonn Titan...</td>\n    </tr>\n    <tr>\n      <th>50422</th>\n      <td>Electronics</td>\n      <td>Samsung Guru FM Plus (SM-B110E/D, Black) Colou...</td>\n    </tr>\n    <tr>\n      <th>50423</th>\n      <td>Electronics</td>\n      <td>Micromax Canvas Win W121 (White)</td>\n    </tr>\n  </tbody>\n</table>\n<p>50424 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/datasets/saurabhshahane/ecommerce-text-classification\n",
    "data = pd.read_csv('ecommerceDataset.csv')\n",
    "data = data.rename(columns={data.columns[0]: 'raw_character_text', data.columns[1]: 'spoken_words'})\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-22T18:34:01.713156700Z",
     "start_time": "2023-05-22T18:34:01.418557700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "raw_character_text    0\nspoken_words          0\ndtype: int64"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# удаляем пустые значения\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "data.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:38:59.269419600Z",
     "start_time": "2023-05-14T13:38:59.246767500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n",
    "\n",
    "def cleaning(doc):\n",
    "    # Lemmatizes and removes stopwords\n",
    "    # doc needs to be a spacy Doc object\n",
    "    txt = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    # Word2Vec uses context words to learn the vector representation of a target word,\n",
    "    # if a sentence is only one or two words long,\n",
    "    # the benefit for the training is very small\n",
    "    if len(txt) > 2:\n",
    "        return ' '.join(txt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:39:01.959555400Z",
     "start_time": "2023-05-14T13:39:01.593803500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in data['spoken_words'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:39:02.049245800Z",
     "start_time": "2023-05-14T13:39:02.047740900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to clean up everything: 7.29 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000, n_process=4)]\n",
    "\n",
    "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:46:22.935365200Z",
     "start_time": "2023-05-14T13:39:05.709417800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "(27160, 1)"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = pd.DataFrame({'clean': txt})\n",
    "df_clean = df_clean.dropna().drop_duplicates()\n",
    "df_clean.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:46:27.251423600Z",
     "start_time": "2023-05-14T13:46:27.130645100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:46:33.870624600Z",
     "start_time": "2023-05-14T13:46:29.077652Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "sent = [row.split() for row in df_clean['clean']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:46:46.274276600Z",
     "start_time": "2023-05-14T13:46:45.095006700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 16:46:46: collecting all words and their counts\n",
      "INFO - 16:46:46: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO - 16:46:47: PROGRESS: at sentence #10000, processed 683487 words and 312227 word types\n",
      "INFO - 16:46:47: PROGRESS: at sentence #20000, processed 1368338 words and 674231 word types\n",
      "INFO - 16:46:48: collected 873513 token types (unigram + bigrams) from a corpus of 1935222 words and 27160 sentences\n",
      "INFO - 16:46:48: merged Phrases<873513 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 16:46:48: Phrases lifecycle event {'msg': 'built Phrases<873513 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000> in 1.42s', 'datetime': '2023-05-14T16:46:48.201147', 'gensim': '4.3.1', 'python': '3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "phrases = Phrases(sent, min_count=30, progress_per=10000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:46:48.208096100Z",
     "start_time": "2023-05-14T13:46:46.778767200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 16:46:50: exporting phrases from Phrases<873513 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 16:46:51: FrozenPhrases lifecycle event {'msg': 'exported FrozenPhrases<1866 phrases, min_count=30, threshold=10.0> from Phrases<873513 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000> in 0.81s', 'datetime': '2023-05-14T16:46:51.556156', 'gensim': '4.3.1', 'python': '3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "bigram = Phraser(phrases)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:46:51.560753200Z",
     "start_time": "2023-05-14T13:46:50.751128100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "sentences = bigram[sent]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:46:52.261925600Z",
     "start_time": "2023-05-14T13:46:52.251044700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "57820"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = defaultdict(int)\n",
    "for sent in sentences:\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:46:55.681129400Z",
     "start_time": "2023-05-14T13:46:54.922040100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "['design', 'book', 'product', 'size', 'set', 'use', 's', 'color', 'x', 'black']"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:46:57.394489900Z",
     "start_time": "2023-05-14T13:46:57.381171900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "from gensim.models import Word2Vec"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:46:59.650259300Z",
     "start_time": "2023-05-14T13:46:59.637757200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:47:02.092802900Z",
     "start_time": "2023-05-14T13:47:02.081106500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 16:47:05: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=300, alpha=0.03>', 'datetime': '2023-05-14T16:47:05.743213', 'gensim': '4.3.1', 'python': '3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec(min_count=20,\n",
    "                     window=2,\n",
    "                     vector_size=300,\n",
    "                     sample=6e-5,\n",
    "                     alpha=0.03,\n",
    "                     min_alpha=0.0007,\n",
    "                     negative=20,\n",
    "                     workers=cores-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:47:05.759188300Z",
     "start_time": "2023-05-14T13:47:05.743213100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 16:47:10: collecting all words and their counts\n",
      "INFO - 16:47:10: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 16:47:11: PROGRESS: at sentence #10000, processed 627309 words, keeping 24107 word types\n",
      "INFO - 16:47:11: PROGRESS: at sentence #20000, processed 1272809 words, keeping 49385 word types\n",
      "INFO - 16:47:11: collected 57820 word types from a corpus of 1791351 raw words and 27160 sentences\n",
      "INFO - 16:47:11: Creating a fresh vocabulary\n",
      "INFO - 16:47:11: Word2Vec lifecycle event {'msg': 'effective_min_count=20 retains 9604 unique words (16.61% of original 57820, drops 48216)', 'datetime': '2023-05-14T16:47:11.790860', 'gensim': '4.3.1', 'python': '3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 16:47:11: Word2Vec lifecycle event {'msg': 'effective_min_count=20 leaves 1637242 word corpus (91.40% of original 1791351, drops 154109)', 'datetime': '2023-05-14T16:47:11.790860', 'gensim': '4.3.1', 'python': '3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 16:47:11: deleting the raw counts dictionary of 57820 items\n",
      "INFO - 16:47:11: sample=6e-05 downsamples 1331 most-common words\n",
      "INFO - 16:47:11: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1050838.5292443614 word corpus (64.2%% of prior 1637242)', 'datetime': '2023-05-14T16:47:11.821072', 'gensim': '4.3.1', 'python': '3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 16:47:11: estimated required memory for 9604 words and 300 dimensions: 27851600 bytes\n",
      "INFO - 16:47:11: resetting layer weights\n",
      "INFO - 16:47:11: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-05-14T16:47:11.871118', 'gensim': '4.3.1', 'python': '3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.02 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.build_vocab(sentences, progress_per=10000)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:47:11.877934200Z",
     "start_time": "2023-05-14T13:47:10.910897500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 16:47:14: Word2Vec lifecycle event {'msg': 'training model with 15 workers on 9604 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2 shrink_windows=True', 'datetime': '2023-05-14T16:47:14.051076', 'gensim': '4.3.1', 'python': '3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "INFO - 16:47:15: EPOCH 0 - PROGRESS: at 43.33% examples, 422814 words/s, in_qsize 28, out_qsize 20\n",
      "INFO - 16:47:15: EPOCH 0: training on 1791351 raw words (1050558 effective words) took 1.7s, 629307 effective words/s\n",
      "INFO - 16:47:16: EPOCH 1 - PROGRESS: at 49.04% examples, 499947 words/s, in_qsize 30, out_qsize 1\n",
      "INFO - 16:47:17: EPOCH 1: training on 1791351 raw words (1050513 effective words) took 2.0s, 535580 effective words/s\n",
      "INFO - 16:47:18: EPOCH 2 - PROGRESS: at 29.33% examples, 283815 words/s, in_qsize 27, out_qsize 3\n",
      "INFO - 16:47:19: EPOCH 2 - PROGRESS: at 61.27% examples, 330317 words/s, in_qsize 26, out_qsize 2\n",
      "INFO - 16:47:20: EPOCH 2: training on 1791351 raw words (1050886 effective words) took 2.8s, 380056 effective words/s\n",
      "INFO - 16:47:21: EPOCH 3 - PROGRESS: at 26.11% examples, 246707 words/s, in_qsize 29, out_qsize 1\n",
      "INFO - 16:47:22: EPOCH 3 - PROGRESS: at 54.54% examples, 291340 words/s, in_qsize 28, out_qsize 4\n",
      "INFO - 16:47:23: EPOCH 3: training on 1791351 raw words (1051281 effective words) took 3.0s, 352277 effective words/s\n",
      "INFO - 16:47:24: EPOCH 4 - PROGRESS: at 29.94% examples, 272404 words/s, in_qsize 29, out_qsize 0\n",
      "INFO - 16:47:25: EPOCH 4 - PROGRESS: at 67.12% examples, 327980 words/s, in_qsize 30, out_qsize 1\n",
      "INFO - 16:47:26: EPOCH 4: training on 1791351 raw words (1050699 effective words) took 2.8s, 375702 effective words/s\n",
      "INFO - 16:47:27: EPOCH 5 - PROGRESS: at 34.32% examples, 326651 words/s, in_qsize 30, out_qsize 1\n",
      "INFO - 16:47:28: EPOCH 5 - PROGRESS: at 70.86% examples, 351986 words/s, in_qsize 23, out_qsize 5\n",
      "INFO - 16:47:29: EPOCH 5: training on 1791351 raw words (1050313 effective words) took 2.6s, 398065 effective words/s\n",
      "INFO - 16:47:30: EPOCH 6 - PROGRESS: at 25.01% examples, 212065 words/s, in_qsize 29, out_qsize 0\n",
      "INFO - 16:47:31: EPOCH 6 - PROGRESS: at 51.06% examples, 247141 words/s, in_qsize 30, out_qsize 1\n",
      "INFO - 16:47:32: EPOCH 6 - PROGRESS: at 93.49% examples, 301156 words/s, in_qsize 15, out_qsize 1\n",
      "INFO - 16:47:32: EPOCH 6: training on 1791351 raw words (1050617 effective words) took 3.3s, 318834 effective words/s\n",
      "INFO - 16:47:33: EPOCH 7 - PROGRESS: at 20.13% examples, 164322 words/s, in_qsize 30, out_qsize 0\n",
      "INFO - 16:47:34: EPOCH 7 - PROGRESS: at 52.92% examples, 262556 words/s, in_qsize 21, out_qsize 3\n",
      "INFO - 16:47:35: EPOCH 7 - PROGRESS: at 93.73% examples, 305304 words/s, in_qsize 15, out_qsize 0\n",
      "INFO - 16:47:35: EPOCH 7: training on 1791351 raw words (1050386 effective words) took 3.3s, 317520 effective words/s\n",
      "INFO - 16:47:36: EPOCH 8 - PROGRESS: at 24.93% examples, 239737 words/s, in_qsize 21, out_qsize 3\n",
      "INFO - 16:47:37: EPOCH 8 - PROGRESS: at 51.83% examples, 271232 words/s, in_qsize 23, out_qsize 4\n",
      "INFO - 16:47:38: EPOCH 8 - PROGRESS: at 82.93% examples, 274950 words/s, in_qsize 29, out_qsize 0\n",
      "INFO - 16:47:39: EPOCH 8: training on 1791351 raw words (1050693 effective words) took 3.4s, 306138 effective words/s\n",
      "INFO - 16:47:40: EPOCH 9 - PROGRESS: at 22.25% examples, 211369 words/s, in_qsize 25, out_qsize 5\n",
      "INFO - 16:47:41: EPOCH 9 - PROGRESS: at 53.87% examples, 285377 words/s, in_qsize 29, out_qsize 0\n",
      "INFO - 16:47:42: EPOCH 9: training on 1791351 raw words (1049950 effective words) took 3.0s, 350075 effective words/s\n",
      "INFO - 16:47:43: EPOCH 10 - PROGRESS: at 22.86% examples, 215072 words/s, in_qsize 29, out_qsize 1\n",
      "INFO - 16:47:44: EPOCH 10 - PROGRESS: at 52.03% examples, 275425 words/s, in_qsize 29, out_qsize 0\n",
      "INFO - 16:47:45: EPOCH 10: training on 1791351 raw words (1050495 effective words) took 3.0s, 350652 effective words/s\n",
      "INFO - 16:47:46: EPOCH 11 - PROGRESS: at 24.61% examples, 230849 words/s, in_qsize 28, out_qsize 3\n",
      "INFO - 16:47:47: EPOCH 11 - PROGRESS: at 61.38% examples, 330202 words/s, in_qsize 30, out_qsize 0\n",
      "INFO - 16:47:47: EPOCH 11: training on 1791351 raw words (1050594 effective words) took 2.7s, 390775 effective words/s\n",
      "INFO - 16:47:49: EPOCH 12 - PROGRESS: at 30.42% examples, 294723 words/s, in_qsize 27, out_qsize 1\n",
      "INFO - 16:47:50: EPOCH 12 - PROGRESS: at 73.34% examples, 367249 words/s, in_qsize 30, out_qsize 1\n",
      "INFO - 16:47:50: EPOCH 12: training on 1791351 raw words (1050914 effective words) took 2.5s, 414121 effective words/s\n",
      "INFO - 16:47:51: EPOCH 13 - PROGRESS: at 30.60% examples, 287349 words/s, in_qsize 28, out_qsize 2\n",
      "INFO - 16:47:52: EPOCH 13 - PROGRESS: at 69.65% examples, 350764 words/s, in_qsize 30, out_qsize 9\n",
      "INFO - 16:47:53: EPOCH 13: training on 1791351 raw words (1051576 effective words) took 2.5s, 415820 effective words/s\n",
      "INFO - 16:47:54: EPOCH 14 - PROGRESS: at 32.02% examples, 312423 words/s, in_qsize 28, out_qsize 2\n",
      "INFO - 16:47:55: EPOCH 14 - PROGRESS: at 76.61% examples, 375813 words/s, in_qsize 30, out_qsize 0\n",
      "INFO - 16:47:55: EPOCH 14: training on 1791351 raw words (1050341 effective words) took 2.5s, 423732 effective words/s\n",
      "INFO - 16:47:56: EPOCH 15 - PROGRESS: at 31.78% examples, 310184 words/s, in_qsize 22, out_qsize 8\n",
      "INFO - 16:47:57: EPOCH 15 - PROGRESS: at 76.50% examples, 375094 words/s, in_qsize 30, out_qsize 2\n",
      "INFO - 16:47:58: EPOCH 15: training on 1791351 raw words (1050658 effective words) took 2.5s, 427362 effective words/s\n",
      "INFO - 16:47:59: EPOCH 16 - PROGRESS: at 32.35% examples, 318470 words/s, in_qsize 26, out_qsize 1\n",
      "INFO - 16:48:00: EPOCH 16 - PROGRESS: at 58.48% examples, 317427 words/s, in_qsize 24, out_qsize 4\n",
      "INFO - 16:48:01: EPOCH 16 - PROGRESS: at 95.99% examples, 330864 words/s, in_qsize 9, out_qsize 1\n",
      "INFO - 16:48:01: EPOCH 16: training on 1791351 raw words (1050219 effective words) took 3.1s, 342194 effective words/s\n",
      "INFO - 16:48:02: EPOCH 17 - PROGRESS: at 30.46% examples, 266400 words/s, in_qsize 29, out_qsize 0\n",
      "INFO - 16:48:03: EPOCH 17 - PROGRESS: at 70.68% examples, 342209 words/s, in_qsize 27, out_qsize 4\n",
      "INFO - 16:48:03: EPOCH 17: training on 1791351 raw words (1050890 effective words) took 2.7s, 396069 effective words/s\n",
      "INFO - 16:48:04: EPOCH 18 - PROGRESS: at 31.86% examples, 316680 words/s, in_qsize 29, out_qsize 0\n",
      "INFO - 16:48:06: EPOCH 18 - PROGRESS: at 63.47% examples, 334129 words/s, in_qsize 30, out_qsize 11\n",
      "INFO - 16:48:06: EPOCH 18: training on 1791351 raw words (1050389 effective words) took 2.6s, 410944 effective words/s\n",
      "INFO - 16:48:07: EPOCH 19 - PROGRESS: at 34.48% examples, 335961 words/s, in_qsize 29, out_qsize 0\n",
      "INFO - 16:48:08: EPOCH 19 - PROGRESS: at 77.06% examples, 384613 words/s, in_qsize 29, out_qsize 0\n",
      "INFO - 16:48:08: EPOCH 19: training on 1791351 raw words (1049805 effective words) took 2.4s, 431681 effective words/s\n",
      "INFO - 16:48:10: EPOCH 20 - PROGRESS: at 32.73% examples, 318879 words/s, in_qsize 25, out_qsize 3\n",
      "INFO - 16:48:11: EPOCH 20 - PROGRESS: at 65.13% examples, 346957 words/s, in_qsize 25, out_qsize 7\n",
      "INFO - 16:48:11: EPOCH 20: training on 1791351 raw words (1050557 effective words) took 2.6s, 405637 effective words/s\n",
      "INFO - 16:48:12: EPOCH 21 - PROGRESS: at 30.45% examples, 292978 words/s, in_qsize 29, out_qsize 1\n",
      "INFO - 16:48:13: EPOCH 21 - PROGRESS: at 68.04% examples, 341779 words/s, in_qsize 29, out_qsize 0\n",
      "INFO - 16:48:14: EPOCH 21: training on 1791351 raw words (1050915 effective words) took 2.7s, 383753 effective words/s\n",
      "INFO - 16:48:15: EPOCH 22 - PROGRESS: at 30.42% examples, 296760 words/s, in_qsize 29, out_qsize 0\n",
      "INFO - 16:48:16: EPOCH 22 - PROGRESS: at 70.10% examples, 350115 words/s, in_qsize 29, out_qsize 0\n",
      "INFO - 16:48:16: EPOCH 22: training on 1791351 raw words (1051268 effective words) took 2.6s, 407141 effective words/s\n",
      "INFO - 16:48:18: EPOCH 23 - PROGRESS: at 29.43% examples, 279997 words/s, in_qsize 30, out_qsize 0\n",
      "INFO - 16:48:19: EPOCH 23 - PROGRESS: at 63.51% examples, 336830 words/s, in_qsize 29, out_qsize 0\n",
      "INFO - 16:48:19: EPOCH 23: training on 1791351 raw words (1050531 effective words) took 2.6s, 397983 effective words/s\n",
      "INFO - 16:48:20: EPOCH 24 - PROGRESS: at 30.45% examples, 292713 words/s, in_qsize 29, out_qsize 0\n",
      "INFO - 16:48:21: EPOCH 24 - PROGRESS: at 67.79% examples, 352583 words/s, in_qsize 29, out_qsize 1\n",
      "INFO - 16:48:22: EPOCH 24: training on 1791351 raw words (1051150 effective words) took 2.5s, 413525 effective words/s\n",
      "INFO - 16:48:23: EPOCH 25 - PROGRESS: at 30.94% examples, 290167 words/s, in_qsize 29, out_qsize 2\n",
      "INFO - 16:48:24: EPOCH 25 - PROGRESS: at 72.67% examples, 356527 words/s, in_qsize 30, out_qsize 1\n",
      "INFO - 16:48:24: EPOCH 25: training on 1791351 raw words (1050371 effective words) took 2.6s, 405525 effective words/s\n",
      "INFO - 16:48:25: EPOCH 26 - PROGRESS: at 16.47% examples, 148805 words/s, in_qsize 28, out_qsize 1\n",
      "INFO - 16:48:27: EPOCH 26 - PROGRESS: at 46.68% examples, 217798 words/s, in_qsize 29, out_qsize 0\n",
      "INFO - 16:48:28: EPOCH 26 - PROGRESS: at 82.59% examples, 259005 words/s, in_qsize 30, out_qsize 1\n",
      "INFO - 16:48:28: EPOCH 26: training on 1791351 raw words (1051757 effective words) took 3.5s, 297979 effective words/s\n",
      "INFO - 16:48:29: EPOCH 27 - PROGRESS: at 22.82% examples, 217124 words/s, in_qsize 29, out_qsize 1\n",
      "INFO - 16:48:30: EPOCH 27 - PROGRESS: at 55.08% examples, 293464 words/s, in_qsize 30, out_qsize 0\n",
      "INFO - 16:48:31: EPOCH 27 - PROGRESS: at 92.73% examples, 316859 words/s, in_qsize 17, out_qsize 0\n",
      "INFO - 16:48:31: EPOCH 27: training on 1791351 raw words (1050999 effective words) took 3.1s, 335687 effective words/s\n",
      "INFO - 16:48:32: EPOCH 28 - PROGRESS: at 21.20% examples, 192030 words/s, in_qsize 22, out_qsize 7\n",
      "INFO - 16:48:33: EPOCH 28 - PROGRESS: at 50.39% examples, 256315 words/s, in_qsize 23, out_qsize 2\n",
      "INFO - 16:48:34: EPOCH 28 - PROGRESS: at 92.08% examples, 309353 words/s, in_qsize 19, out_qsize 0\n",
      "INFO - 16:48:34: EPOCH 28: training on 1791351 raw words (1050672 effective words) took 3.2s, 328629 effective words/s\n",
      "INFO - 16:48:35: EPOCH 29 - PROGRESS: at 21.79% examples, 169847 words/s, in_qsize 25, out_qsize 2\n",
      "INFO - 16:48:36: EPOCH 29 - PROGRESS: at 48.63% examples, 227679 words/s, in_qsize 28, out_qsize 1\n",
      "INFO - 16:48:37: EPOCH 29 - PROGRESS: at 96.06% examples, 310857 words/s, in_qsize 9, out_qsize 1\n",
      "INFO - 16:48:38: EPOCH 29: training on 1791351 raw words (1050223 effective words) took 3.3s, 321824 effective words/s\n",
      "INFO - 16:48:38: Word2Vec lifecycle event {'msg': 'training on 53740530 raw words (31520220 effective words) took 84.0s, 375305 effective words/s', 'datetime': '2023-05-14T16:48:38.034650', 'gensim': '4.3.1', 'python': '3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 1.4 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:48:38.050620Z",
     "start_time": "2023-05-14T13:47:14.051076900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vital\\AppData\\Local\\Temp\\ipykernel_15208\\2897808894.py:1: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v_model.init_sims(replace=True)\n",
      "WARNING - 17:06:10: destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n"
     ]
    }
   ],
   "source": [
    "w2v_model.init_sims(replace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T14:06:11.006870800Z",
     "start_time": "2023-05-14T14:06:10.996901600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "[('colour', 0.7377306222915649),\n ('white', 0.46367552876472473),\n ('size', 0.44954991340637207),\n ('dark_brown', 0.4471963942050934),\n ('coloured', 0.4401470422744751),\n ('sky_blue', 0.4386478066444397),\n ('x_inch', 0.4343136250972748),\n ('yellow', 0.425954133272171),\n ('cmx', 0.42519354820251465),\n ('orchid', 0.41912955045700073)]"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# топ-N наиболее похожих ключей.\n",
    "w2v_model.wv.most_similar(positive=[\"color\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T14:06:11.383133100Z",
     "start_time": "2023-05-14T14:06:11.367415400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "[('item', 0.4581340551376343),\n ('reasonable_price', 0.43712934851646423),\n ('customer', 0.40329709649086),\n ('pricing', 0.39780914783477783),\n ('quality', 0.3960415720939636),\n ('brand', 0.3846954107284546),\n ('customer_service', 0.37859463691711426),\n ('raw_material', 0.36219289898872375),\n ('place_order', 0.35821089148521423),\n ('warranty_manufacturing', 0.349313884973526)]"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# топ-N наиболее похожих ключей.\n",
    "w2v_model.wv.most_similar(positive=[\"product\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T14:06:11.811692800Z",
     "start_time": "2023-05-14T14:06:11.801074900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "0.36100146"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вычислите косинусное сходство между двумя ключами.\n",
    "w2v_model.wv.similarity('customer_service', 'reasonable_price')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T14:06:12.217021100Z",
     "start_time": "2023-05-14T14:06:12.207831300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "'place_order'"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Какой ключ из приведенного списка не подходит к остальным?\n",
    "w2v_model.wv.doesnt_match(['dark_brown', 'yellow', 'place_order'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T14:06:12.569555200Z",
     "start_time": "2023-05-14T14:06:12.558037300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "[('forzza', 0.31910401582717896),\n ('cum_bed', 0.28673428297042847),\n ('ttk_prestige', 0.28248220682144165)]"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Какое слово относится к brand также, как x_inch к place_order\n",
    "w2v_model.wv.most_similar(positive=[\"brand\", \"dark_brown\"], negative=[\"orchid\"], topn=3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T14:06:13.346915900Z",
     "start_time": "2023-05-14T14:06:13.326850700Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
