{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import re  # For preprocessing\n",
    "import pandas as pd  # For data handling\n",
    "from time import time  # To time our operations\n",
    "from collections import defaultdict  # For word frequency\n",
    "\n",
    "import spacy  # For preprocessing\n",
    "\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:31:37.143909600Z",
     "start_time": "2023-05-14T13:31:37.134703300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "             raw_character_text   \n0                   Miss Hoover  \\\n1                  Lisa Simpson   \n2                   Miss Hoover   \n3                  Lisa Simpson   \n4       Edna Krabappel-Flanders   \n...                         ...   \n158309              Miss Hoover   \n158310              Miss Hoover   \n158311              Miss Hoover   \n158312             Ralph Wiggum   \n158313                    JANEY   \n\n                                             spoken_words  \n0       No, actually, it was a little of both. Sometim...  \n1                                  Where's Mr. Bergstrom?  \n2       I don't know. Although I'd sure like to talk t...  \n3                              That life is worth living.  \n4       The polls will be open from now until the end ...  \n...                                                   ...  \n158309                                          I'm back.  \n158310  You see, class, my Lyme disease turned out to ...  \n158311                                 Psy-cho-so-ma-tic.  \n158312                     Does that mean you were crazy?  \n158313                  No, that means she was faking it.  \n\n[158314 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>raw_character_text</th>\n      <th>spoken_words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Miss Hoover</td>\n      <td>No, actually, it was a little of both. Sometim...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Lisa Simpson</td>\n      <td>Where's Mr. Bergstrom?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Miss Hoover</td>\n      <td>I don't know. Although I'd sure like to talk t...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Lisa Simpson</td>\n      <td>That life is worth living.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Edna Krabappel-Flanders</td>\n      <td>The polls will be open from now until the end ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>158309</th>\n      <td>Miss Hoover</td>\n      <td>I'm back.</td>\n    </tr>\n    <tr>\n      <th>158310</th>\n      <td>Miss Hoover</td>\n      <td>You see, class, my Lyme disease turned out to ...</td>\n    </tr>\n    <tr>\n      <th>158311</th>\n      <td>Miss Hoover</td>\n      <td>Psy-cho-so-ma-tic.</td>\n    </tr>\n    <tr>\n      <th>158312</th>\n      <td>Ralph Wiggum</td>\n      <td>Does that mean you were crazy?</td>\n    </tr>\n    <tr>\n      <th>158313</th>\n      <td>JANEY</td>\n      <td>No, that means she was faking it.</td>\n    </tr>\n  </tbody>\n</table>\n<p>158314 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/code/pierremegret/gensim-word2vec-tutorial\n",
    "data = pd.read_csv('simpsons_dataset.csv')\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:50:17.787581900Z",
     "start_time": "2023-05-14T13:50:17.678445Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "raw_character_text    0\nspoken_words          0\ndtype: int64"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# удаляем пустые значения\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "data.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:50:18.390594100Z",
     "start_time": "2023-05-14T13:50:18.358057500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n",
    "\n",
    "def cleaning(doc):\n",
    "    # Lemmatizes and removes stopwords\n",
    "    # doc needs to be a spacy Doc object\n",
    "    txt = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    # Word2Vec uses context words to learn the vector representation of a target word,\n",
    "    # if a sentence is only one or two words long,\n",
    "    # the benefit for the training is very small\n",
    "    if len(txt) > 2:\n",
    "        return ' '.join(txt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:50:19.324785100Z",
     "start_time": "2023-05-14T13:50:18.840826600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in data['spoken_words'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:50:19.405568200Z",
     "start_time": "2023-05-14T13:50:19.396436900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to clean up everything: 1.75 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000, n_process=-1)]\n",
    "\n",
    "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:52:04.847376600Z",
     "start_time": "2023-05-14T13:50:19.940791400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "(85955, 1)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = pd.DataFrame({'clean': txt})\n",
    "df_clean = df_clean.dropna().drop_duplicates()\n",
    "df_clean.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:52:04.950844600Z",
     "start_time": "2023-05-14T13:52:04.850952100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:52:05.383753300Z",
     "start_time": "2023-05-14T13:52:04.950844600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "sent = [row.split() for row in df_clean['clean']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:52:05.576045800Z",
     "start_time": "2023-05-14T13:52:05.383753300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 16:52:05: collecting all words and their counts\n",
      "INFO - 16:52:05: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO - 16:52:05: PROGRESS: at sentence #10000, processed 63557 words and 52723 word types\n",
      "INFO - 16:52:05: PROGRESS: at sentence #20000, processed 130936 words and 99612 word types\n",
      "INFO - 16:52:05: PROGRESS: at sentence #30000, processed 192961 words and 138181 word types\n",
      "INFO - 16:52:05: PROGRESS: at sentence #40000, processed 249832 words and 172156 word types\n",
      "INFO - 16:52:05: PROGRESS: at sentence #50000, processed 311269 words and 207943 word types\n",
      "INFO - 16:52:05: PROGRESS: at sentence #60000, processed 373578 words and 242950 word types\n",
      "INFO - 16:52:05: PROGRESS: at sentence #70000, processed 436424 words and 277852 word types\n",
      "INFO - 16:52:06: PROGRESS: at sentence #80000, processed 497887 words and 310927 word types\n",
      "INFO - 16:52:06: collected 329641 token types (unigram + bigrams) from a corpus of 537095 words and 85955 sentences\n",
      "INFO - 16:52:06: merged Phrases<329641 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 16:52:06: Phrases lifecycle event {'msg': 'built Phrases<329641 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000> in 0.47s', 'datetime': '2023-05-14T16:52:06.050537', 'gensim': '4.3.1', 'python': '3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "phrases = Phrases(sent, min_count=30, progress_per=10000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:52:06.053044700Z",
     "start_time": "2023-05-14T13:52:05.576045800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 16:52:06: exporting phrases from Phrases<329641 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 16:52:06: FrozenPhrases lifecycle event {'msg': 'exported FrozenPhrases<128 phrases, min_count=30, threshold=10.0> from Phrases<329641 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000> in 0.35s', 'datetime': '2023-05-14T16:52:06.410696', 'gensim': '4.3.1', 'python': '3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "bigram = Phraser(phrases)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:52:06.415190400Z",
     "start_time": "2023-05-14T13:52:06.053044700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "sentences = bigram[sent]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:52:06.421067600Z",
     "start_time": "2023-05-14T13:52:06.418449Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "29694"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = defaultdict(int)\n",
    "for sent in sentences:\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:52:06.800626Z",
     "start_time": "2023-05-14T13:52:06.422485300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "['oh', 'like', 'know', 'get', 'hey', 'think', 'come', 'right', 'look', 'want']"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:52:06.810556Z",
     "start_time": "2023-05-14T13:52:06.800626Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "from gensim.models import Word2Vec"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:52:06.822122600Z",
     "start_time": "2023-05-14T13:52:06.810556Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:52:06.827676600Z",
     "start_time": "2023-05-14T13:52:06.822122600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 16:52:06: Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=300, alpha=0.03>', 'datetime': '2023-05-14T16:52:06.830794', 'gensim': '4.3.1', 'python': '3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec(min_count=20,\n",
    "                     window=2,\n",
    "                     vector_size=300,\n",
    "                     sample=6e-5,\n",
    "                     alpha=0.03,\n",
    "                     min_alpha=0.0007,\n",
    "                     negative=20,\n",
    "                     workers=cores-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:52:06.840522Z",
     "start_time": "2023-05-14T13:52:06.830794400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 16:52:06: collecting all words and their counts\n",
      "INFO - 16:52:06: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 16:52:06: PROGRESS: at sentence #10000, processed 61697 words, keeping 9518 word types\n",
      "INFO - 16:52:06: PROGRESS: at sentence #20000, processed 127312 words, keeping 14384 word types\n",
      "INFO - 16:52:07: PROGRESS: at sentence #30000, processed 187772 words, keeping 17442 word types\n",
      "INFO - 16:52:07: PROGRESS: at sentence #40000, processed 243265 words, keeping 20121 word types\n",
      "INFO - 16:52:07: PROGRESS: at sentence #50000, processed 303120 words, keeping 22551 word types\n",
      "INFO - 16:52:07: PROGRESS: at sentence #60000, processed 363858 words, keeping 24820 word types\n",
      "INFO - 16:52:07: PROGRESS: at sentence #70000, processed 425311 words, keeping 26987 word types\n",
      "INFO - 16:52:07: PROGRESS: at sentence #80000, processed 485433 words, keeping 28822 word types\n",
      "INFO - 16:52:07: collected 29694 word types from a corpus of 523538 raw words and 85955 sentences\n",
      "INFO - 16:52:07: Creating a fresh vocabulary\n",
      "INFO - 16:52:07: Word2Vec lifecycle event {'msg': 'effective_min_count=20 retains 3325 unique words (11.20% of original 29694, drops 26369)', 'datetime': '2023-05-14T16:52:07.317580', 'gensim': '4.3.1', 'python': '3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 16:52:07: Word2Vec lifecycle event {'msg': 'effective_min_count=20 leaves 438016 word corpus (83.66% of original 523538, drops 85522)', 'datetime': '2023-05-14T16:52:07.317580', 'gensim': '4.3.1', 'python': '3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 16:52:07: deleting the raw counts dictionary of 29694 items\n",
      "INFO - 16:52:07: sample=6e-05 downsamples 1198 most-common words\n",
      "INFO - 16:52:07: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 199427.65110464947 word corpus (45.5%% of prior 438016)', 'datetime': '2023-05-14T16:52:07.333308', 'gensim': '4.3.1', 'python': '3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 16:52:07: estimated required memory for 3325 words and 300 dimensions: 9642500 bytes\n",
      "INFO - 16:52:07: resetting layer weights\n",
      "INFO - 16:52:07: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-05-14T16:52:07.350740', 'gensim': '4.3.1', 'python': '3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'build_vocab'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.01 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.build_vocab(sentences, progress_per=10000)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:52:07.361996500Z",
     "start_time": "2023-05-14T13:52:06.834409700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 16:52:07: Word2Vec lifecycle event {'msg': 'training model with 15 workers on 3325 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2 shrink_windows=True', 'datetime': '2023-05-14T16:52:07.365016', 'gensim': '4.3.1', 'python': '3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "INFO - 16:52:08: EPOCH 0: training on 523538 raw words (199584 effective words) took 0.8s, 260772 effective words/s\n",
      "INFO - 16:52:08: EPOCH 1: training on 523538 raw words (199638 effective words) took 0.7s, 299671 effective words/s\n",
      "INFO - 16:52:09: EPOCH 2: training on 523538 raw words (199401 effective words) took 0.8s, 255415 effective words/s\n",
      "INFO - 16:52:10: EPOCH 3: training on 523538 raw words (199017 effective words) took 0.8s, 244027 effective words/s\n",
      "INFO - 16:52:11: EPOCH 4: training on 523538 raw words (199060 effective words) took 0.8s, 239077 effective words/s\n",
      "INFO - 16:52:12: EPOCH 5: training on 523538 raw words (199618 effective words) took 0.9s, 221737 effective words/s\n",
      "INFO - 16:52:13: EPOCH 6 - PROGRESS: at 86.65% examples, 172700 words/s, in_qsize 7, out_qsize 1\n",
      "INFO - 16:52:13: EPOCH 6: training on 523538 raw words (199541 effective words) took 1.1s, 189925 effective words/s\n",
      "INFO - 16:52:14: EPOCH 7 - PROGRESS: at 45.74% examples, 89691 words/s, in_qsize 28, out_qsize 1\n",
      "INFO - 16:52:14: EPOCH 7: training on 523538 raw words (199133 effective words) took 1.2s, 172108 effective words/s\n",
      "INFO - 16:52:15: EPOCH 8: training on 523538 raw words (199592 effective words) took 0.7s, 280799 effective words/s\n",
      "INFO - 16:52:16: EPOCH 9: training on 523538 raw words (199264 effective words) took 1.0s, 207174 effective words/s\n",
      "INFO - 16:52:17: EPOCH 10: training on 523538 raw words (199375 effective words) took 0.7s, 270308 effective words/s\n",
      "INFO - 16:52:17: EPOCH 11: training on 523538 raw words (199047 effective words) took 0.8s, 261186 effective words/s\n",
      "INFO - 16:52:18: EPOCH 12: training on 523538 raw words (199613 effective words) took 0.7s, 270285 effective words/s\n",
      "INFO - 16:52:19: EPOCH 13: training on 523538 raw words (199486 effective words) took 0.8s, 247772 effective words/s\n",
      "INFO - 16:52:20: EPOCH 14: training on 523538 raw words (199221 effective words) took 0.7s, 282558 effective words/s\n",
      "INFO - 16:52:20: EPOCH 15: training on 523538 raw words (199603 effective words) took 0.8s, 252119 effective words/s\n",
      "INFO - 16:52:21: EPOCH 16: training on 523538 raw words (199151 effective words) took 0.8s, 258940 effective words/s\n",
      "INFO - 16:52:22: EPOCH 17: training on 523538 raw words (199171 effective words) took 0.7s, 292528 effective words/s\n",
      "INFO - 16:52:23: EPOCH 18: training on 523538 raw words (199588 effective words) took 0.8s, 265872 effective words/s\n",
      "INFO - 16:52:24: EPOCH 19: training on 523538 raw words (199212 effective words) took 0.8s, 256930 effective words/s\n",
      "INFO - 16:52:24: EPOCH 20: training on 523538 raw words (199363 effective words) took 0.8s, 249687 effective words/s\n",
      "INFO - 16:52:25: EPOCH 21: training on 523538 raw words (199640 effective words) took 0.8s, 248178 effective words/s\n",
      "INFO - 16:52:26: EPOCH 22: training on 523538 raw words (199156 effective words) took 0.8s, 241156 effective words/s\n",
      "INFO - 16:52:27: EPOCH 23: training on 523538 raw words (199630 effective words) took 0.9s, 213838 effective words/s\n",
      "INFO - 16:52:28: EPOCH 24: training on 523538 raw words (199711 effective words) took 0.8s, 243203 effective words/s\n",
      "INFO - 16:52:29: EPOCH 25: training on 523538 raw words (199623 effective words) took 0.9s, 220358 effective words/s\n",
      "INFO - 16:52:30: EPOCH 26 - PROGRESS: at 22.18% examples, 45263 words/s, in_qsize 30, out_qsize 0\n",
      "INFO - 16:52:30: EPOCH 26: training on 523538 raw words (199682 effective words) took 1.3s, 149052 effective words/s\n",
      "INFO - 16:52:31: EPOCH 27: training on 523538 raw words (199521 effective words) took 1.0s, 200478 effective words/s\n",
      "INFO - 16:52:32: EPOCH 28: training on 523538 raw words (199640 effective words) took 0.9s, 216098 effective words/s\n",
      "INFO - 16:52:33: EPOCH 29 - PROGRESS: at 33.79% examples, 67600 words/s, in_qsize 30, out_qsize 0\n",
      "INFO - 16:52:33: EPOCH 29: training on 523538 raw words (199342 effective words) took 1.2s, 162925 effective words/s\n",
      "INFO - 16:52:33: Word2Vec lifecycle event {'msg': 'training on 15706140 raw words (5982623 effective words) took 26.5s, 226112 effective words/s', 'datetime': '2023-05-14T16:52:33.820313', 'gensim': '4.3.1', 'python': '3.11.3 (tags/v3.11.3:f3909b8, Apr  4 2023, 23:49:59) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 0.44 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:52:33.830498Z",
     "start_time": "2023-05-14T13:52:07.365016300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vital\\AppData\\Local\\Temp\\ipykernel_6260\\2897808894.py:1: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v_model.init_sims(replace=True)\n",
      "WARNING - 16:52:33: destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n"
     ]
    }
   ],
   "source": [
    "w2v_model.init_sims(replace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:52:33.840317200Z",
     "start_time": "2023-05-14T13:52:33.833527500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "[('marge', 0.7253799438476562),\n ('depressed', 0.6885277628898621),\n ('convince', 0.6841305494308472),\n ('fault', 0.6789838671684265),\n ('sweetheart', 0.6788270473480225),\n ('tab', 0.6756338477134705),\n ('teeny', 0.6755796074867249),\n ('ask', 0.6725385785102844),\n ('straighten', 0.6678181886672974),\n ('crummy', 0.6669281721115112)]"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"homer\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T13:52:33.865004400Z",
     "start_time": "2023-05-14T13:52:33.840317200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "[('congratulation', 0.7026652693748474),\n ('select', 0.6953061819076538),\n ('council', 0.6940925717353821),\n ('versus', 0.6886987686157227),\n ('robert', 0.673720121383667),\n ('charles', 0.6649235486984253),\n ('request', 0.6641824245452881),\n ('brief', 0.6627007722854614),\n ('simon', 0.6583764553070068),\n ('threat', 0.6580336689949036)]"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"homer_simpson\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T09:49:24.599050600Z",
     "start_time": "2023-05-14T09:49:24.540319400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "[('homer', 0.7770687341690063),\n ('homie', 0.7143275141716003),\n ('becky', 0.7051325440406799),\n ('darling', 0.6850861310958862),\n ('ned', 0.6842876672744751),\n ('want', 0.6806071996688843),\n ('snuggle', 0.6760526895523071),\n ('ashamed', 0.6747106313705444),\n ('grownup', 0.6661184430122375),\n ('fault', 0.6644595861434937)]"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"marge\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T09:49:24.599997600Z",
     "start_time": "2023-05-14T09:49:24.551692400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "[('lisa', 0.7836252450942993),\n ('homework', 0.7634544372558594),\n ('mom_dad', 0.7293103337287903),\n ('pay_attention', 0.7222058176994324),\n ('mom', 0.7120025753974915),\n ('substitute', 0.7105140686035156),\n ('hearing', 0.7104999423027039),\n ('creepy', 0.7030847072601318),\n ('milhouse', 0.6877204775810242),\n ('bedtime', 0.6859204173088074)]"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"bart\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T09:49:24.599997600Z",
     "start_time": "2023-05-14T09:49:24.562257700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "0.57336015"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity('bart', 'nelson')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T09:49:24.599997600Z",
     "start_time": "2023-05-14T09:49:24.572914200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 12:49:24: vectors for words {'kearney'} are not present in the model, ignoring these words\n"
     ]
    },
    {
     "data": {
      "text/plain": "'jimbo'"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.doesnt_match(['jimbo', 'milhouse', 'kearney'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T09:49:24.599997600Z",
     "start_time": "2023-05-14T09:49:24.581709Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "'nelson'"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.doesnt_match([\"nelson\", \"bart\", \"milhouse\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T09:49:24.599997600Z",
     "start_time": "2023-05-14T09:49:24.591681900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "'homer'"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.doesnt_match(['homer', 'patty', 'selma'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T09:49:24.619313600Z",
     "start_time": "2023-05-14T09:49:24.601643700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "[('admire', 0.5814297199249268),\n ('reason', 0.5814090967178345),\n ('man', 0.5605944395065308)]"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"woman\", \"homer\"], negative=[\"marge\"], topn=3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T09:49:24.620312200Z",
     "start_time": "2023-05-14T09:49:24.609825400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "[('lisa', 0.6816440224647522),\n ('pay_attention', 0.6672130823135376),\n ('pregnant', 0.631349503993988)]"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"woman\", \"bart\"], negative=[\"man\"], topn=3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T09:49:24.636445100Z",
     "start_time": "2023-05-14T09:49:24.620312200Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
